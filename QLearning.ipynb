{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10| 1.00|\n",
      "---------------------------\n",
      "-0.10| 0.00|-0.10|-1.00|\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10|-0.10|\n",
      "it: 0\n",
      "it: 2000\n",
      "it: 4000\n",
      "it: 6000\n",
      "it: 8000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRwx9SeoRQ1+SeuT/A3nuUBhSbX6sAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update counts:\n",
      "---------------------------\n",
      " 0.26| 0.05| 0.04| 0.00|\n",
      "---------------------------\n",
      " 0.12| 0.00| 0.01| 0.00|\n",
      "---------------------------\n",
      " 0.28| 0.07| 0.05| 0.11|\n",
      "values:\n",
      "---------------------------\n",
      " 0.62| 0.80| 1.00| 0.00|\n",
      "---------------------------\n",
      " 0.46| 0.00| 0.80| 0.00|\n",
      "---------------------------\n",
      " 0.31| 0.46| 0.62| 0.46|\n",
      "policy:\n",
      "---------------------------\n",
      "  R  |  R  |  R  |     |\n",
      "---------------------------\n",
      "  U  |     |  U  |     |\n",
      "---------------------------\n",
      "  U  |  R  |  U  |  L  |\n"
     ]
    }
   ],
   "source": [
    "# https://deeplearningcourses.com/c/artificial-intelligence-reinforcement-learning-in-python\n",
    "# https://www.udemy.com/artificial-intelligence-reinforcement-learning-in-python\n",
    "from __future__ import print_function, division\n",
    "from builtins import range\n",
    "# Note: you may need to update your version of future\n",
    "# sudo pip install -U future\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from grid_world import standard_grid, negative_grid\n",
    "from iterative_policy_evaluation import print_values, print_policy\n",
    "from monte_carlo_es import max_dict\n",
    "from td0_prediction import random_action\n",
    "\n",
    "GAMMA = 0.9\n",
    "ALPHA = 0.25\n",
    "ALL_POSSIBLE_ACTIONS = ('U', 'D', 'L', 'R')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  # NOTE: if we use the standard grid, there's a good chance we will end up with\n",
    "  # suboptimal policies\n",
    "  # e.g.\n",
    "  # ---------------------------\n",
    "  #   R  |   R  |   R  |      |\n",
    "  # ---------------------------\n",
    "  #   R* |      |   U  |      |\n",
    "  # ---------------------------\n",
    "  #   U  |   R  |   U  |   L  |\n",
    "  # since going R at (1,0) (shown with a *) incurs no cost, it's OK to keep doing that.\n",
    "  # we'll either end up staying in the same spot, or back to the start (2,0), at which\n",
    "  # point we whould then just go back up, or at (0,0), at which point we can continue\n",
    "  # on right.\n",
    "  # instead, let's penalize each movement so the agent will find a shorter route.\n",
    "  #\n",
    "  # grid = standard_grid()\n",
    "  grid = negative_grid(step_cost=-0.1)\n",
    "\n",
    "  # print rewards\n",
    "  print(\"rewards:\")\n",
    "  print_values(grid.rewards, grid)\n",
    "\n",
    "  # no policy initialization, we will derive our policy from most recent Q\n",
    "\n",
    "  # initialize Q(s,a)\n",
    "  Q = {}\n",
    "  states = grid.all_states()\n",
    "  for s in states:\n",
    "    Q[s] = {}\n",
    "    for a in ALL_POSSIBLE_ACTIONS:\n",
    "      Q[s][a] = 0\n",
    "\n",
    "  # let's also keep track of how many times Q[s] has been updated\n",
    "  update_counts = {}\n",
    "  update_counts_sa = {}\n",
    "  for s in states:\n",
    "    update_counts_sa[s] = {}\n",
    "    for a in ALL_POSSIBLE_ACTIONS:\n",
    "      update_counts_sa[s][a] = 1.0\n",
    "\n",
    "  # repeat until convergence\n",
    "  t = 1.0\n",
    "  deltas = []\n",
    "  for it in range(10000):\n",
    "    if it % 100 == 0:\n",
    "      t += 1e-2\n",
    "    if it % 2000 == 0:\n",
    "      print(\"it:\", it)\n",
    "\n",
    "    # instead of 'generating' an epsiode, we will PLAY\n",
    "    # an episode within this loop\n",
    "    s = (2, 0) # start state\n",
    "    grid.set_state(s)\n",
    "\n",
    "    # the first (s, r) tuple is the state we start in and 0\n",
    "    # (since we don't get a reward) for simply starting the game\n",
    "    # the last (s, r) tuple is the terminal state and the final reward\n",
    "    # the value for the terminal state is by definition 0, so we don't\n",
    "    # care about updating it.\n",
    "    a, _ = max_dict(Q[s])\n",
    "    biggest_change = 0\n",
    "    while not grid.game_over():\n",
    "      a = random_action(a, eps=0.5/t) # epsilon-greedy\n",
    "      # random action also works, but slower since you can bump into walls\n",
    "      # a = np.random.choice(ALL_POSSIBLE_ACTIONS)\n",
    "      r = grid.move(a)\n",
    "      s2 = grid.current_state()\n",
    "\n",
    "      # adaptive learning rate\n",
    "      alpha = ALPHA / update_counts_sa[s][a]\n",
    "      update_counts_sa[s][a] += 0.005\n",
    "\n",
    "      # we will update Q(s,a) AS we experience the episode\n",
    "      old_qsa = Q[s][a]\n",
    "      # the difference between SARSA and Q-Learning is with Q-Learning\n",
    "      # we will use this max[a']{ Q(s',a')} in our update\n",
    "      # even if we do not end up taking this action in the next step\n",
    "      a2, max_q_s2a2 = max_dict(Q[s2])\n",
    "      Q[s][a] = Q[s][a] + alpha*(r + GAMMA*max_q_s2a2 - Q[s][a])\n",
    "      biggest_change = max(biggest_change, np.abs(old_qsa - Q[s][a]))\n",
    "\n",
    "      # we would like to know how often Q(s) has been updated too\n",
    "      update_counts[s] = update_counts.get(s,0) + 1\n",
    "\n",
    "      # next state becomes current state\n",
    "      s = s2\n",
    "     \n",
    "    deltas.append(biggest_change)\n",
    "\n",
    "  plt.plot(deltas)\n",
    "  plt.show()\n",
    "\n",
    "  # determine the policy from Q*\n",
    "  # find V* from Q*\n",
    "  policy = {}\n",
    "  V = {}\n",
    "  for s in grid.actions.keys():\n",
    "    a, max_q = max_dict(Q[s])\n",
    "    policy[s] = a\n",
    "    V[s] = max_q\n",
    "\n",
    "  # what's the proportion of time we spend updating each part of Q?\n",
    "  print(\"update counts:\")\n",
    "  total = np.sum(list(update_counts.values()))\n",
    "  for k, v in update_counts.items():\n",
    "    update_counts[k] = float(v) / total\n",
    "  print_values(update_counts, grid)\n",
    "\n",
    "  print(\"values:\")\n",
    "  print_values(V, grid)\n",
    "  print(\"policy:\")\n",
    "  print_policy(policy, grid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
